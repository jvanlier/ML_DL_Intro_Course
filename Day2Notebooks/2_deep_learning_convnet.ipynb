{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvNet classifier\n",
    "=================\n",
    "\n",
    "The second exercise is to build a Convolutional Neural Network to distuingish dogs from cats.\n",
    "\n",
    "**Important: before you start, click \"Runtime\" in the top menu, then \"Change runtime type\", and ensure that Hardware accelerator \"GPU\" is selected. This should speed things up considerably.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DIR = Path(\"/tmp\")\n",
    "ZIPFILE = TMP_DIR / \"cats_and_dogs_filtered.zip\"\n",
    "BASE_DIR = TMP_DIR / \"cats_and_dogs_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O $ZIPFILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipf = zipfile.ZipFile(ZIPFILE, \"r\")\n",
    "zipf.extractall(TMP_DIR)\n",
    "zipf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we just downloaded! We will use the linux command `ls`. The exclamation mark tells the notebook that we're executing a command-line instruction istead of a Python instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $BASE_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $BASE_DIR/train/dogs|head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $BASE_DIR/train/cats|head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some convenient variables to access these directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = BASE_DIR / \"train\"\n",
    "VAL_DIR = BASE_DIR / \"validation\"\n",
    "\n",
    "TRAIN_DOG_DIR = TRAIN_DIR / \"dogs\"\n",
    "TRAIN_CAT_DIR = TRAIN_DIR / \"cats\"\n",
    "\n",
    "VAL_DOG_DIR = VAL_DIR / \"dogs\"\n",
    "VAL_CAT_DIR = VAL_DIR / \"cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(TRAIN_DOG_DIR / \"dog.0.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(TRAIN_CAT_DIR / \"cat.0.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to convince yourself that the other images are also dogs and cats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is this dataset balanced or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(TRAIN_DOG_DIR.glob(\"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: check the number of files in TRAIN_CAT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you conclude on the use of the **accuracy** metric for this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple ConvNet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: check the dimensions of the images.**\n",
    "\n",
    "Use `plt.imread()`, as above, to read on the cat or dog images. This function returns a numpy array. Check the shape of the numpy array.\n",
    "\n",
    "For example, if `a` is a numpy array, you may call `a.shape` to get the shape.\n",
    "\n",
    "The shape is in `(y, x, depth)`: the number of pixels in the y-direction (height), the number of pixels in the x-direction (width) and the number of channels (3 for each primary color). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assign **half** of these numbers to DIM_Y and DIM_X below.\n",
    "That's right, we're resizing the image to be half of the original. This speeds things up and still allows us to reach reasonable performance.\n",
    "\n",
    "**Tip: make sure DIM_Y and DIM_X are integers! Use type(var) to confirm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_Y = # YOUR CODE HERE\n",
    "DIM_X = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to build the model.\n",
    "\n",
    "We will build 3 groups of Convolution + MaxPooling. The first group has already been initialized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 3, input_shape=(DIM_Y, DIM_X, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second group, add a Conv2D with 32 filters, a ReLU activation, and a MaxPooling2D with pool size of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third group is the same, except increase the number of convolution filters to 64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `Flatten()` to go back to 1 dimension, and add a fully-connected layer with 512 nodes. Use `Dense(512)` to do that. Finally, use the ReLU activation function again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end with a Sigmoid node (`Dense(1)` with sigmoid activation function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(DIM_Y, DIM_X),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(DIM_Y, DIM_X),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=1000 // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did this go? Did you manage to get reasonable accuracy?\n",
    "You might notice that it's overfitting pretty heavily. Let's see what we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentations\n",
    "\n",
    "Getting more training data usually helps with the overfitting problem. One cheap way to easily get more training data, is by \"augmenting\" the existing data. We can create new training images by applying random transformations on the existing images.\n",
    "\n",
    "In the `ImageDataGenerator` above, that we assigned to `train_datagen`, we can add optional transformations.\n",
    "For example:\n",
    "\n",
    "    shear_range=0.1,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True \n",
    "    \n",
    "Below, we'll define a new `ImageDataGenerator` with augmentations. Select a couple from above, or all, and feel free to change parameters to get more or less extreme augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen_aug = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    # YOUR CODE HERE: data augmentations\n",
    ")\n",
    "train_generator_aug = train_datagen_aug.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(DIM_Y, DIM_X),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(train_generator_aug)[0]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.imshow(batch[i, :])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't go overboard: make sure it still looks realistic to the human eye. Tweak as necessary.\n",
    "\n",
    "Let's see if this helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = Sequential()\n",
    "model_aug.add(Conv2D(16, 3, input_shape=(DIM_Y, DIM_X, 3)))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(MaxPooling2D(pool_size=2))\n",
    "model_aug.add(Conv2D(32, 3))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(MaxPooling2D(pool_size=2))\n",
    "model_aug.add(Conv2D(64, 3))\n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(MaxPooling2D(pool_size=2))\n",
    "model_aug.add(Flatten()) \n",
    "model_aug.add(Dense(512)) \n",
    "model_aug.add(Activation('relu'))\n",
    "model_aug.add(Dense(1))\n",
    "model_aug.add(Activation('sigmoid'))\n",
    "model_aug.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_aug.fit_generator(\n",
    "        train_generator_aug, # This uses the new augmentated data generator!\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=1000 // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude about the effect of the data augmentations?\n",
    "\n",
    "Some tips:\n",
    "- If train and test accuracy are pretty close, but the accuracy is on the low side, try making the augmentations *less* extreme. I.e. lower the parameters, or take some (unrealistic) augmentations out completely. There seems to be an underfitting problem.\n",
    "- If train and test accuracy are still pretty far apart, try making the augmentations *more* extreme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's output some of the model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(in_images):\n",
    "    for img in in_images:\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0) / 255\n",
    "        yield x\n",
    "        \n",
    "def show(model_):\n",
    "    pred_class_label_map = {0: \"cats\", 1: \"dogs\"}\n",
    "    actual_labels = 8 * [\"cats\"] + 8 * [\"dogs\"]\n",
    "    random_img_paths = np.concatenate((np.random.choice(list(VAL_CAT_DIR.glob(\"*.jpg\")), 8),\n",
    "                                       np.random.choice(list(VAL_DOG_DIR.glob(\"*.jpg\")), 8)))\n",
    "    random_imgs = [image.load_img(file, target_size=(DIM_Y, DIM_X)) for file in random_img_paths]\n",
    "    random_imgs_processed = list(process_images(random_imgs))\n",
    "\n",
    "    # Predict:\n",
    "    images = np.vstack(random_imgs_processed) \n",
    "    pred_classes = model_.predict_classes(images, batch_size=16).ravel()\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 16))\n",
    "\n",
    "    for img, ax, actual_label, pred_class in zip(random_imgs_processed, axes.ravel(), actual_labels, pred_classes):\n",
    "        pred_label = pred_class_label_map[pred_class]\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        result = \"ok\" if actual_label == pred_label else \"NOK\"\n",
    "        ax.set_title(\"{}, y={}, {}={}\".format(result, actual_label, '$\\hat{y}$', pred_label))\n",
    "        ax.imshow(img.squeeze())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(model_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open-ended bonus assignments\n",
    "- Try increasing the representation size. Earlier, we only used half of the image. Does it help if we use 100% of the image?\n",
    "- Overfitting can also be reduced by including a Dropout layer. Dropout randomly zeroes out neurons, which makes the model generalize better. Try putting a `Dropout(0.5)` between the Dense(512) and the Dense(1) layer, after the ReLU activation.\n",
    "- Try increasing or decreasing the number of convolution filters, adding another block of Conv2D and MaxPooling, taking out a block or increasing or decreasing the number of nodes in the fully connected (Dense) layer. Sometimes it helps to add a second fully connected (Dense) layer. \n",
    "    - Note: It is definitely possible to improve on this simple Convolutional Neural Network, but you'll probably find that iterating towards the optimal architecture is quite difficult and time consuming. Welcome to the everyday challenges of a data scientist :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
