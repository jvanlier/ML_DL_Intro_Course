{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhVxFBTV6MwV"
   },
   "source": [
    "Neural Network Classification\n",
    "========================\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Run each cell from top to bottom. Try to understand the output of each command. If in doubt, ask your neighbours or the instructor(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MqfvuI1N6MwY",
    "outputId": "a0e7d83c-8679-4287-9f9d-7a76a1aa2889"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2zG5ozpi6Mwc"
   },
   "source": [
    "We will load a dataset from the US census bureau. We are going to predict whether a person makes more than $ 50K a year, or less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "nctAund16Mwd",
    "outputId": "d644a734-6b1d-4a92-91b1-19508af7dc3a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>more-than-50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex  capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country  more-than-50k  \n",
       "0             0              40   United-States              0  \n",
       "1             0              13   United-States              0  \n",
       "2             0              40   United-States              0  \n",
       "3             0              40   United-States              0  \n",
       "4             0              40            Cuba              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/jvanlier/ML_DL_Intro_Course/master/Day2Notebooks/data/census.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhW3VWcK6Mwg"
   },
   "source": [
    "Below are some more details about this dataset:\n",
    "\n",
    "\n",
    "- `age`: continuous.\n",
    "- `workclass`: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "- `education`: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, - 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "- `education-num`: continuous.\n",
    "- `marital-status`: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "- `occupation`: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "- `relationship`: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "- `race`: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "- `sex`: Female, Male.\n",
    "- `capital-gain`: continuous.\n",
    "- `capital-loss`: continuous.\n",
    "- `hours-per-week`: continuous.\n",
    "- `native-country`: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Note that there are many textual columns, which are somewhat annoying to deal with.\n",
    "\n",
    "Our target is column `more-than-50k`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-i8sOPr16Mwh"
   },
   "source": [
    "Luckily, we can use `pd.get_dummies` to OneHotEncode the dataset easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "C7KgvXTR6Mwh",
    "outputId": "2e10f1ed-8f36-4519-e5c4-c382fd4e2508"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>more-than-50k</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_ Portugal</th>\n",
       "      <th>native-country_ Puerto-Rico</th>\n",
       "      <th>native-country_ Scotland</th>\n",
       "      <th>native-country_ South</th>\n",
       "      <th>native-country_ Taiwan</th>\n",
       "      <th>native-country_ Thailand</th>\n",
       "      <th>native-country_ Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_ United-States</th>\n",
       "      <th>native-country_ Vietnam</th>\n",
       "      <th>native-country_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39             13          2174             0              40   \n",
       "1   50             13             0             0              13   \n",
       "2   38              9             0             0              40   \n",
       "3   53              7             0             0              40   \n",
       "4   28             13             0             0              40   \n",
       "\n",
       "   more-than-50k  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0              0                       0                     0   \n",
       "1              0                       0                     0   \n",
       "2              0                       0                     0   \n",
       "3              0                       0                     0   \n",
       "4              0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private  ...  native-country_ Portugal  \\\n",
       "0                        0                   0  ...                         0   \n",
       "1                        0                   0  ...                         0   \n",
       "2                        0                   1  ...                         0   \n",
       "3                        0                   1  ...                         0   \n",
       "4                        0                   1  ...                         0   \n",
       "\n",
       "   native-country_ Puerto-Rico  native-country_ Scotland  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "\n",
       "   native-country_ South  native-country_ Taiwan  native-country_ Thailand  \\\n",
       "0                      0                       0                         0   \n",
       "1                      0                       0                         0   \n",
       "2                      0                       0                         0   \n",
       "3                      0                       0                         0   \n",
       "4                      0                       0                         0   \n",
       "\n",
       "   native-country_ Trinadad&Tobago  native-country_ United-States  \\\n",
       "0                                0                              1   \n",
       "1                                0                              1   \n",
       "2                                0                              1   \n",
       "3                                0                              1   \n",
       "4                                0                              0   \n",
       "\n",
       "   native-country_ Vietnam  native-country_ Yugoslavia  \n",
       "0                        0                           0  \n",
       "1                        0                           0  \n",
       "2                        0                           0  \n",
       "3                        0                           0  \n",
       "4                        0                           0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFva7ewq6Mwk"
   },
   "source": [
    "Let's take a look at the skew in the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Ntw78bOD6Mwk",
    "outputId": "83a5d4c7-cea8-4cc0-e90d-8e48da0518db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24720\n",
       "1     7841\n",
       "Name: more-than-50k, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ohe[\"more-than-50k\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AvVTEqQ6Mwn"
   },
   "source": [
    "Yes, it's fairly skewed with many more 0 instances than 1 instances. Let's use the F1 score this time, instead of Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxctvGtb6Mwo"
   },
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SJvA3s9a6Mwp"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uZwAJaHT6Mwr",
    "outputId": "8d3309f1-87af-45a2-fe4c-2f480c321f23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26048 training instances and 6513 test instances.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_ohe.drop(\"more-than-50k\", axis=1), \n",
    "    df_ohe[\"more-than-50k\"], \n",
    "    test_size=0.2, \n",
    "    random_state=0)\n",
    "print(f\"{len(X_train)} training instances and {len(X_test)} test instances.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylk9vdfE6Mwu"
   },
   "source": [
    "### Baseline\n",
    "Before we start diving into Neural Nets, let's first try setting a baseline with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uaZjitEU6Mwv"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV(scoring=\"f1\", max_iter=1000, cv=3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxVWGSFc6Mwy"
   },
   "source": [
    "LogisticRegressionCV uses an internal cross-validation loop to find a good value for the regularization parameter. This, as we know by now, helps with the overfitting problem.\n",
    "\n",
    "As a warm-up, start with a fit on the training data. This should be familiar after last week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "F0MGQVHG6Mwz",
    "outputId": "448c3adc-7781-4eee-940d-ec78c2983802"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=3, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=1000,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=0,\n",
       "           refit=True, scoring='f1', solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7rEbFXo6Mw1"
   },
   "source": [
    "Score the model on both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "mmLnjn2O6Mw2",
    "outputId": "79f80450-777e-4840-872c-5af6c47bcd58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.6526259186234092\n",
      "Test score 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jvlier/pyvenvs/deepturn_v6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n",
      "/Users/jvlier/pyvenvs/deepturn_v6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1917: ChangedBehaviorWarning: The long-standing behavior to use the accuracy score has changed. The scoring parameter is now used. This warning will disappear in version 0.22.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score\", lr.score(X_train, y_train))\n",
    "print(\"Test score\", lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ga0Vse2F6Mw6"
   },
   "source": [
    "It could also be useful to take a look at the confusion matrix. This came up briefly last week. It contains the number of True Postives, False Positives, False Negatives and True Negatives.\n",
    "\n",
    "Take a look at the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azQv7o2q6Mw7"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: import confusion matrix (hint: see top of documentation page for import path)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Sdr8Xvw16Mw9",
    "outputId": "b58cc35d-bd6e-4ac8-ea07-a8538f5b4d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4581,  337],\n",
       "       [ 652,  943]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE: create confusion matrix (hint: you need to pass it predictions on X_test)\n",
    "confusion_matrix(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_M9btdjB6Mw_"
   },
   "source": [
    "How many True Negatives do you have? And how many True Positives? Refer to the documentation to find out what each cell in the confusion matrix means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cb3J5dQf6MxA"
   },
   "source": [
    "## Neural Networks\n",
    "Let's now try to improve on this result by moving towards a more complex model.\n",
    "\n",
    "`scikit-learn` provides a basic neural network, but it's not really used a lot. Most practitioners prefer Keras or PyTorch. We'll use Keras, which is backed by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRakTci76MxB"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N84VYu3x6MxD"
   },
   "source": [
    "We'll start by making a network that mimicks Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50DO1tzo6MxE"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)  # Leave this here! It ensures reproducability of results.\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_yPj2sr36MxH"
   },
   "source": [
    "Now, we need to add just the single sigmoid node. In Keras terminology, this is a `Dense` layer, with a single unit.\n",
    "\n",
    "To initialize a dense layer, with 1 unit, `m` input features, and sigmoid activation function, use the following:\n",
    "\n",
    "`dense = Dense(1, input_dim=m, activation=\"sigmoid\")`\n",
    "\n",
    "To figure out what `m` is, you may use `X_train.shape` or `len(X_train.columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g58OGgMG_LcM",
    "outputId": "a867b271-5e3d-4fec-d180-e07efa2effc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26048, 99)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation: number of columns is second element of this tuple.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJTFtNKp6MxI"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: create dense layer\n",
    "dense = Dense(1, input_dim=X_train.shape[1], activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9X2BQyR6MxN"
   },
   "source": [
    "Now add your layer to the model using `model.add(...)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LZqdmqw6MxO"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: add dense layer to model\n",
    "model.add(dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLpRzNi26MxQ"
   },
   "source": [
    "The following command tells Keras how to optimize and evaluate the model. Unfortunately, there is no easy way to show F1 score during optimization, so will check it afterwards. \n",
    "\n",
    "You hopefully remember *binary crossentropy* from last week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u92iGwBu6MxR"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",  optimizer=Adam(lr=0.0003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zd9JI2_56MxT"
   },
   "source": [
    "The following command starts training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1730
    },
    "colab_type": "code",
    "id": "iDlVd_516MxT",
    "outputId": "ab83b2e9-8cbc-4acb-cf2e-9f26de23d212",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/50\n",
      "26048/26048 [==============================] - 0s 15us/step - loss: 9.6900 - val_loss: 8.3717\n",
      "Epoch 2/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 7.1039 - val_loss: 5.6398\n",
      "Epoch 3/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 4.4082 - val_loss: 3.0515\n",
      "Epoch 4/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 2.2102 - val_loss: 1.5146\n",
      "Epoch 5/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 1.4299 - val_loss: 1.2921\n",
      "Epoch 6/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 1.3452 - val_loss: 1.2697\n",
      "Epoch 7/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 1.3318 - val_loss: 1.2610\n",
      "Epoch 8/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 1.3236 - val_loss: 1.2531\n",
      "Epoch 9/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 1.3158 - val_loss: 1.2451\n",
      "Epoch 10/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 1.3078 - val_loss: 1.2370\n",
      "Epoch 11/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 1.2986 - val_loss: 1.2153\n",
      "Epoch 12/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.8573 - val_loss: 0.7802\n",
      "Epoch 13/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.8087 - val_loss: 0.7822\n",
      "Epoch 14/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.8010 - val_loss: 0.7656\n",
      "Epoch 15/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7935 - val_loss: 0.7552\n",
      "Epoch 16/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7846 - val_loss: 0.7472\n",
      "Epoch 17/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 0.7796 - val_loss: 0.7470\n",
      "Epoch 18/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7716 - val_loss: 0.7337\n",
      "Epoch 19/50\n",
      "26048/26048 [==============================] - 0s 5us/step - loss: 0.7661 - val_loss: 0.7285\n",
      "Epoch 20/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7589 - val_loss: 0.7240\n",
      "Epoch 21/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7543 - val_loss: 0.7184\n",
      "Epoch 22/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7490 - val_loss: 0.7123\n",
      "Epoch 23/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7447 - val_loss: 0.7163\n",
      "Epoch 24/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7416 - val_loss: 0.7051\n",
      "Epoch 25/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7363 - val_loss: 0.6996\n",
      "Epoch 26/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7344 - val_loss: 0.6983\n",
      "Epoch 27/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7299 - val_loss: 0.6980\n",
      "Epoch 28/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7256 - val_loss: 0.6903\n",
      "Epoch 29/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7246 - val_loss: 0.6936\n",
      "Epoch 30/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7221 - val_loss: 0.6843\n",
      "Epoch 31/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7195 - val_loss: 0.6823\n",
      "Epoch 32/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7170 - val_loss: 0.6803\n",
      "Epoch 33/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7165 - val_loss: 0.6775\n",
      "Epoch 34/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7108 - val_loss: 0.6799\n",
      "Epoch 35/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7097 - val_loss: 0.6738\n",
      "Epoch 36/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7077 - val_loss: 0.6722\n",
      "Epoch 37/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7063 - val_loss: 0.6764\n",
      "Epoch 38/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7053 - val_loss: 0.6686\n",
      "Epoch 39/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.7059 - val_loss: 0.6692\n",
      "Epoch 40/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7017 - val_loss: 0.6680\n",
      "Epoch 41/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.7024 - val_loss: 0.6669\n",
      "Epoch 42/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.6995 - val_loss: 0.6694\n",
      "Epoch 43/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.6977 - val_loss: 0.6634\n",
      "Epoch 44/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.4412 - val_loss: 0.3597\n",
      "Epoch 45/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.3441 - val_loss: 0.3532\n",
      "Epoch 46/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3439 - val_loss: 0.3524\n",
      "Epoch 47/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3436 - val_loss: 0.3552\n",
      "Epoch 48/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3421 - val_loss: 0.3492\n",
      "Epoch 49/50\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.3426 - val_loss: 0.3504\n",
      "Epoch 50/50\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3418 - val_loss: 0.3481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1308a11d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=200, \n",
    "          validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io_PrPor6MxV"
   },
   "source": [
    "50 epochs should get you a validation loss of approximately 0.35."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vk7B45Q36MxW"
   },
   "source": [
    "Ok, now let's see the F1 score. First, we have to get predicted classes. Use `model.predict_classes(...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZQGILKQ6MxX"
   },
   "outputs": [],
   "source": [
    "y_test_hat = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJ6KvM-j6MxZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r3yV5dPj6Mxa",
    "outputId": "99496ef0-6f41-4386-c6bf-41099607ba72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6240352811466373"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_test_hat)\n",
    "# YOUR CODE HERE: use f1_score function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLzntb5j6Mxd"
   },
   "source": [
    "How do you feel about this F1 score? Disappointing?\n",
    "\n",
    "Well, that's as expected!\n",
    "\n",
    "The Logistic Regression implementation in scikit-learn uses a very sophisticated optimizer (L-BFGS). Neural Networks use less sophisticated optimizers (backpropagation with gradient descent), which makes them harder to train. You need to get many things right: e.g. number of epochs, batch size and learning rate. However, the less sophisticated optimizer used in Neural Networks *does* allows us to do backpropagation and update hidden layers, which we shall do soon!\n",
    "\n",
    "But first, try running the `fit()` method again and see if this improves the F1 score? In contrast to scikit-learn, repeated calls to this `fit()` method do not overwrite the previous model, but in fact continue training! You may run this command multiple times, until you no longer see `val_loss` improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "id": "lSHwx_rZ6Mxe",
    "outputId": "7e6d8b01-d39e-4c41-9fa3-a3c01f054705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3317 - val_loss: 0.3423\n",
      "Epoch 2/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3318 - val_loss: 0.3461\n",
      "Epoch 3/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3327 - val_loss: 0.3399\n",
      "Epoch 4/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3437 - val_loss: 0.3498\n",
      "Epoch 5/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3335 - val_loss: 0.3418\n",
      "Epoch 6/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3312 - val_loss: 0.3429\n",
      "Epoch 7/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3322 - val_loss: 0.3518\n",
      "Epoch 8/20\n",
      "26048/26048 [==============================] - 0s 8us/step - loss: 0.3314 - val_loss: 0.3446\n",
      "Epoch 9/20\n",
      "26048/26048 [==============================] - 0s 8us/step - loss: 0.3297 - val_loss: 0.3403\n",
      "Epoch 10/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3306 - val_loss: 0.3415\n",
      "Epoch 11/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3307 - val_loss: 0.3545\n",
      "Epoch 12/20\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.3303 - val_loss: 0.3416\n",
      "Epoch 13/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3307 - val_loss: 0.3408\n",
      "Epoch 14/20\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.3304 - val_loss: 0.3389\n",
      "Epoch 15/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3313 - val_loss: 0.3385\n",
      "Epoch 16/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3296 - val_loss: 0.3405\n",
      "Epoch 17/20\n",
      "26048/26048 [==============================] - 0s 6us/step - loss: 0.3308 - val_loss: 0.3384\n",
      "Epoch 18/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3324 - val_loss: 0.3433\n",
      "Epoch 19/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3294 - val_loss: 0.3410\n",
      "Epoch 20/20\n",
      "26048/26048 [==============================] - 0s 7us/step - loss: 0.3297 - val_loss: 0.3394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130b9eb38>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE: Run fit() again with 20 epochs. \n",
    "# Keep everything else the same. Feel free to copy paste the command!\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=200, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8QrWpiI6Mxg"
   },
   "source": [
    "What is the F1 score now? Did training longer improve things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zV8HFHrd6Mxi",
    "outputId": "0d4e4d46-cd01-4e0e-cc61-dc9c6f85375c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6570048309178744"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE: what is the F1 score now? \n",
    "y_test_hat = model.predict_classes(X_test)\n",
    "f1_score(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oservation: got .657 after running the fit method 2 times (so +40 epochs).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69Z20Kul6Mxj"
   },
   "source": [
    "# Going deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ii8QYgXS6Mxk"
   },
   "source": [
    "Now, build a new neural network with a Dense hidden layer. It is defined much like before, although now, use 200 nodes instead of 1, and use tanh activation function instead of sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8CMbwu706Mxl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model2 = Sequential()\n",
    "hidden_layer = Dense(200, input_dim=99, activation=\"tanh\")\n",
    "model2.add(hidden_layer)\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=0.0003))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "CyMxg38B6Mxn",
    "outputId": "ff3cf5c7-208d-48d5-b3fb-510f91522d8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26048 samples, validate on 6513 samples\n",
      "Epoch 1/10\n",
      "26048/26048 [==============================] - 0s 10us/step - loss: 0.3196 - val_loss: 0.3302\n",
      "Epoch 2/10\n",
      "26048/26048 [==============================] - 0s 9us/step - loss: 0.3191 - val_loss: 0.3340\n",
      "Epoch 3/10\n",
      "26048/26048 [==============================] - 0s 10us/step - loss: 0.3180 - val_loss: 0.3308\n",
      "Epoch 4/10\n",
      "26048/26048 [==============================] - 0s 10us/step - loss: 0.3181 - val_loss: 0.3320\n",
      "Epoch 5/10\n",
      "26048/26048 [==============================] - 0s 11us/step - loss: 0.3193 - val_loss: 0.3319\n",
      "Epoch 6/10\n",
      "26048/26048 [==============================] - 0s 10us/step - loss: 0.3178 - val_loss: 0.3332\n",
      "Epoch 7/10\n",
      "26048/26048 [==============================] - 0s 9us/step - loss: 0.3169 - val_loss: 0.3325\n",
      "Epoch 8/10\n",
      "26048/26048 [==============================] - 0s 9us/step - loss: 0.3171 - val_loss: 0.3282\n",
      "Epoch 9/10\n",
      "26048/26048 [==============================] - 0s 10us/step - loss: 0.3153 - val_loss: 0.3296\n",
      "Epoch 10/10\n",
      "26048/26048 [==============================] - 0s 9us/step - loss: 0.3156 - val_loss: 0.3297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6695166063794805"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, epochs=10, batch_size=200, validation_data=[X_test, y_test])\n",
    "f1_score(y_test, model2.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMuM3xk6Mxq"
   },
   "source": [
    "You should be able to get .67 - .68 after around 30 epochs. Run the cell above a couple of times. This a small - but not insignificant - improvement over simple Logistic Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGqg-3-A6Mxr"
   },
   "source": [
    "# Open ended bonus assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSgVsa5x6Mxr"
   },
   "source": [
    "- Add a second hidden layer. Can you improve the score?\n",
    "- Try tuning the learning rate, batch size, number of hidden nodes. What is the best F1 score you can get?\n",
    "- Try training a Random Forest like we did last week. Feel free to copy-paste the appropriate bits of code from that notebook. How does the Random Forest compare to the Neural Network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 1_neural_network_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
