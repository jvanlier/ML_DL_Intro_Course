{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Mall_Customers.csv\")\n",
    "df.columns = [\"CustomerID\", \"Gender\", \"Age\", \"Income\", \"Spending\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "We need to do some pre-processing before we can cluster this dataset.\n",
    "\n",
    "Obviously CustomerID is isn't informative, so we can drop that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to Gender. It is a string, but strings can't be inserted into a Machine Learning algorithm. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, only two genders in this dataset. We can *One Hot Encode* this into a new variable `isFemale`.\n",
    "\n",
    "You can call the `.map()` function on any column in a DataFrame, to map or convert all values in that column to new values. The *mapping* needs to be specified as a *dictionary*.\n",
    "\n",
    "For example, to map `Foo` to 1, and `Bar` to 2, you would pass the following dictionary to `map()`:\n",
    "\n",
    "```\n",
    "{\"Foo\": 1,\n",
    " \"Bar\": 2}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"isFemale\"] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can drop Gender column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should standardize the variables such that they're on the same scale.\n",
    "\n",
    "Most scikit-learn experts would use `sklearn.preprocessing.StandardScaler`, but it is a bit complicated to use. We can also do this ourselves quite easily.\n",
    "\n",
    "A simple way to standardize values, is to subtract the mean, and divide the result by the standard deviation.\n",
    "\n",
    "You can get the mean and standard deviation like this:\n",
    "\n",
    "    df[\"column\"].mean()\n",
    "    df[\"column\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy()\n",
    "\n",
    "for col in df_scaled.columns:\n",
    "    df_scaled[col] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you think about operator precedence? Remember that `/` is evaluated before `-`. Use brackets appropriately.\n",
    "\n",
    "Let's see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, initialize KMeans with 3 clusters. Refer to the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) if needed.\n",
    "\n",
    "Also, make sure to use `random_state=42` to ensure we all get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit to `df_scaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict `df_scaled`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this doesn't make a lot of sense yet. Let's add these to the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df.copy().assign(cluster=clusters)\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to figure out if these clusters make sense. Maybe we can describe each cluster and assign names to them? We are now going to have to make some plots to figure out in what way the clusters differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"cluster\", y=\"Age\", data=df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: check out all variables and see how the clusters differ. Boxplots are good, but you might also like `violinplot`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also nice to visualize them in a scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Age\" \n",
    "y = \"Spending\"\n",
    "\n",
    "for cluster in df_cluster[\"cluster\"].unique():\n",
    "    df_cluster_single = df_cluster[df_cluster[\"cluster\"] == cluster]\n",
    "    plt.scatter(df_cluster_single[x], df_cluster_single[y], label=f\"Cluster: {cluster}\")\n",
    "plt.legend()\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "Think of a name for each cluster, based on their properties!\n",
    "\n",
    "- Cluster 0:\n",
    "- Cluster 1:\n",
    "- Cluster 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open ended bonus assignments\n",
    "- Try increasing the number of clusters. Do you (still) get sensible results?\n",
    "- Do 10 fits, with number of clusters from 1 to 10. For each fit, grab the `_intertia` value. Plot this in a graph and perform the *elbow method* to find the optimal number of clusters.\n",
    "- Try clustering the wine quality dataset and see what interesting things you can find."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
