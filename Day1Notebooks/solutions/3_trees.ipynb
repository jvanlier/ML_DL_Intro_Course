{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 3_trees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "aududHitaWZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBab7S-KaWZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/tmp/wine-binary.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnAHEHZsaWZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(\"isGood\", axis=1), df[\"isGood\"],\n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vw4FDsEHaWZN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Simple decision tree"
      ]
    },
    {
      "metadata": {
        "id": "icU4kng8aWZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoHP7J15aWZQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, try initializing the model and doing a fit on the wine dataset."
      ]
    },
    {
      "metadata": {
        "id": "Ddofkei6aWZR",
        "colab_type": "code",
        "outputId": "22a1b989-863b-49f7-d41a-58df7739efee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "gRDIoWwsaWZT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Take a look at the train & test scores. How does this compare to Logistic Regression the results?"
      ]
    },
    {
      "metadata": {
        "id": "q-vL0QB5aWZU",
        "colab_type": "code",
        "outputId": "f0bc9709-dce1-4988-c901-cb5e46f19537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.score(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "0zAkolgyaWZW",
        "colab_type": "code",
        "outputId": "57c57798-0f2a-43e5-9727-daa34e8c0a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#model.score(... # YOUR CODE HERE\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "NyyTf17NaWZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How would you explain the gap between the training set and test set performance?\n",
        "\n",
        "Let's see if can reduce the gap a bit... check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) and see if there's any way to reduce the complexity of the model to bring train and test closer together (ideally, test score should go up and as a side-effect, train score goes down)."
      ]
    },
    {
      "metadata": {
        "id": "7RWMi6ZLaWZZ",
        "colab_type": "code",
        "outputId": "9dc4a389-339f-454a-d91e-1666f22e16e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE: Initialize DecisionTreeClassifier with one or more parameters, fit and evaluate.\n",
        "model_reg = DecisionTreeClassifier(max_depth=7, min_samples_split=4, min_samples_leaf=6)\n",
        "model_reg.fit(X_train, y_train)\n",
        "print(model_reg.score(X_train, y_train))\n",
        "print(model_reg.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8498748957464554\n",
            "0.7275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dkt-f-ofaWZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "During the wrap up, we'll see who managed to get the highest score and which parameters values were used (I'm trying to appeal to your competetive spirit here ;-))"
      ]
    },
    {
      "metadata": {
        "id": "E5NNHbwQaWZd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You might notice that it's pretty difficult solve the overfitting problem with a Decision Tree. \n",
        "\n",
        "Luckily, Random Forests help out in this aspect. \n",
        "\n",
        "# Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "OLrWG4gyaWZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFthQXotaWZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "48MFWpK3aWZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try setting a first baseline fit with default parameters first. "
      ]
    },
    {
      "metadata": {
        "id": "ETmAyl-HaWZm",
        "colab_type": "code",
        "outputId": "4f3b9be0-e223-4c5e-effb-1f838162206c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "rf.fit(X_train, y_train)\n",
        "print(rf.score(X_train, y_train))\n",
        "print(rf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9933277731442869\n",
            "0.785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aWsbmwyJaWZn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What do you notice, compared to the decision tree performance?\n",
        "\n",
        "Try running the model multiple times. Why do you get different scores in each try?"
      ]
    },
    {
      "metadata": {
        "id": "b3zkZGVGaWZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ok, let's try playing with the parameters. Some things you can do:\n",
        "- Bumping `n_estimators` to 20, 50, 100\n",
        "- Limiting `max_depth` to 5, 10, 15"
      ]
    },
    {
      "metadata": {
        "id": "9CzLjtTbaWZo",
        "colab_type": "code",
        "outputId": "e95f77de-a003-4ed8-fed1-b285955d6027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
        "rf.fit(X_train, y_train)\n",
        "print(rf.score(X_train, y_train))\n",
        "print(rf.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R-LvsnX5aWZr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Grid Search\n",
        "Luckily, we can automate this parameter-finding process."
      ]
    },
    {
      "metadata": {
        "id": "kzh6VwLUaWZs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIh7_QBoaWZu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
      ]
    },
    {
      "metadata": {
        "id": "V0zz34dRaWZu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Complete the grid below using the options in the RandomForestClassifier documention page. Pick a couple you find interesting (not too many!)"
      ]
    },
    {
      "metadata": {
        "id": "W6DkvBgjaWZv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"n_estimators\": [10, 50, 250, 500, 1000],\n",
        "    # YOUR PARAMS HERE\n",
        "    \"max_depth\": [10, 15, 20, 25],\n",
        "    \"min_samples_split\": [2, 3],\n",
        "    \"min_samples_leaf\": [1, 2, 3]\n",
        "} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sk7xP-Y7aWZz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gcv = GridSearchCV(RandomForestClassifier(), param_grid, cv=3, n_jobs=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "arRTtvIKaWZ2",
        "colab_type": "code",
        "outputId": "eb3a38d7-61de-4fd7-db21-0bfac6896405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "gcv.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False),\n",
              "       fit_params=None, iid='warn', n_jobs=8,\n",
              "       param_grid={'n_estimators': [10, 50, 250, 500, 1000], 'max_depth': [10, 15, 20, 25], 'min_samples_split': [2, 3], 'min_samples_leaf': [1, 2, 3]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "N8D3bCLRaWZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What are your best parameters?"
      ]
    },
    {
      "metadata": {
        "id": "tXPlVdzkaWZ5",
        "colab_type": "code",
        "outputId": "edb44695-2a0e-4e6d-8c91-5c898149d4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gcv.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 15,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'n_estimators': 250}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "l03WTNBoaWZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And what is the associated Cross Validation score?"
      ]
    },
    {
      "metadata": {
        "id": "jCHFqwhuaWZ8",
        "colab_type": "code",
        "outputId": "f4906f26-724e-49d3-f92f-02bd5e545655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "gcv.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7939949958298582"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "Fp5P6y8SaWZ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And the score on the test set, with the best model according to the grid search?"
      ]
    },
    {
      "metadata": {
        "id": "yvkyRtTtaWZ-",
        "colab_type": "code",
        "outputId": "55e71e35-adb2-47ae-9718-b989f9069f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE\n",
        "print(gcv.score(X_test, y_test))\n",
        "#or:\n",
        "gcv.best_estimator_.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "QcbjzfwhaWaA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Open-ended bonus assignments\n",
        "- Try using RandomizedSearchCV instead of GridSearchCV\n",
        "- Try inspecting the RandomForestClassifier model to see if you can get a better understanding of what the model is doing. Hint: look up `feature_importances`.\n",
        "- Instead of using Accuracy, see if you can get Precision, Recall and F1 score metrics. The scikit-learn documentation should help. "
      ]
    },
    {
      "metadata": {
        "id": "mOiG32E-aWaB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}